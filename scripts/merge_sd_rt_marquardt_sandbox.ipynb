{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "Processing 27\n",
      "Remote: found 329 files\n",
      ".........................................................................................................................................................................................................................................................................................................................................\n",
      "SD: found 768 files\n",
      "................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "sddir = \"/home/maik/b2drop/cosmicsense/inbox/marquardt/timeseries/crns/sd\"\n",
    "remotedir = \"/home/maik/b2drop/cosmicsense/inbox/marquardt/timeseries/crns/remote\"\n",
    "trgdir = \"/media/x/cosmicsense/data/marquardt/crns\"\n",
    "tmpfile = \"tmpfile.txt\"\n",
    "tmpfile2 = \"tmpfile2.txt\"\n",
    "ids = [1, 2, 4, 21, 22, 26, 27, 28]\n",
    "ids = [27]\n",
    "\n",
    "crns = {\n",
    "     1: {\"remotepattern\": \"up1_Data*.001*.txt\",\n",
    "         \"sdpattern\": \"*.001\",\n",
    "         \"colnames\": [\"rec_id\", \"datetime\", \"press1\", \"temp1\", \"relhum1\", \"volt\", \"counts1\", \"nsecs1\", \"counts2\", \"nsecs2\"]},\n",
    "\n",
    "     2: {\"remotepattern\": \"up2_Data*.002*.txt\",\n",
    "         \"sdpattern\": \"*.002\",\n",
    "         \"colnames\": [\"rec_id\", \"datetime\", \"press1\", \"temp1\", \"relhum1\", \"volt\", \"counts1\", \"nsecs1\"]\n",
    "        },\n",
    "\n",
    "     4: {\"remotepattern\": \"up4_Data*.004*.txt\",\n",
    "         \"sdpattern\": \"*.004\",\n",
    "         \"colnames\": [\"rec_id\", \"datetime\", \"press1\", \"temp1\", \"relhum1\", \"volt\",\n",
    "                      \"counts1\", \"nsecs1\", \"counts2\", \"nsecs2\", \"MetOne092_1\",\"press4\",\"temp_ext\",\n",
    "                      \"relhum_ext\",\"N1T_C\",\"N1RH\",\"N2T_C\",\"N2RH\"]\n",
    "        },\n",
    "\n",
    "    21: {\"remotepattern\": \"CRSProbe_Data*.021*.txt\",\n",
    "          \"sdpattern\": \"*.021\",\n",
    "          \"colnames\": [\"rec_id\", \"datetime\", \"press1\", \"press4\", \"temp1\",\"relhum1\", \"temp_ext\",\n",
    "                       \"relhum_ext\", \"volt\", \"counts1\", \"nsecs1\", \"N1T_C\", \"N1RH\"]\n",
    "        },\n",
    "\n",
    "    22: {\"remotepattern\": \"CRSProbe_Data*.022*.txt\",\n",
    "         \"sdpattern\": \"*.022\",\n",
    "         \"colnames\": [\"rec_id\", \"datetime\", \"press1\", \"press4\", \"temp1\",\"relhum1\", \"temp_ext\",\n",
    "                       \"relhum_ext\", \"volt\", \"counts1\", \"nsecs1\", \"N1T_C\", \"N1RH\"]\n",
    "        },\n",
    "\n",
    "    26: {\"remotepattern\": \"up26_Data*.026*.txt\",\n",
    "         \"sdpattern\": \"*.026\",\n",
    "         \"colnames\": [\"rec_id\", \"datetime\", \"press1\", \"press4\", \"temp1\", \"relhum1\", \"volt\", \"counts1\", \"nsecs1\", \"counts2\", \"nsecs2\"]\n",
    "        },\n",
    "\n",
    "    27: {\"remotepattern\": \"up27_Data*.027*.txt\",\n",
    "         \"sdpattern\": \"*.027\",\n",
    "         \"colnames\": [\"rec_id\", \"datetime\", \"press1\", \"temp1\", \"relhum1\",\n",
    "                      \"volt\", \"counts1\", \"nsecs1\", \"counts2\", \"nsecs2\"],\n",
    "         \"colnames2\": [\"rec_id\", \"datetime\", \"press1\", \"temp1\", \"relhum1\",\n",
    "                      \"volt\", \"counts1\", \"nsecs1\", \"counts3\", \"nsecs3\", \"counts2\", \"nsecs2\"]\n",
    "\n",
    "        },\n",
    "\n",
    "    28: {\"remotepattern\": \"sonde28_Data_*.028*\",\n",
    "         \"sdpattern\": \"*.028\",\n",
    "         \"colnames\": [\"rec_id\", \"datetime\", \"press1\", \"press4\", \"temp1\", \"relhum1\", \"volt\", \"counts1\", \"nsecs1\", \"temp2\", \"relhum2\"]\n",
    "        }\n",
    "}\n",
    "\n",
    "\n",
    "for i, id in enumerate(ids):\n",
    "    print(\"-------------\")\n",
    "    print(\"Processing %d\" % id)\n",
    "\n",
    "    try:\n",
    "        os.remove(tmpfile)\n",
    "        os.remove(tmpfile2)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # REMOTE FILES\n",
    "    print(\"Remote: \", end=\"\")\n",
    "    searchdir = os.path.join(remotedir,\"%d\" % id, crns[id][\"remotepattern\"])\n",
    "    remotefiles = glob.glob(searchdir, recursive=True)\n",
    "    print(\"found %d files\" % len(remotefiles))\n",
    "\n",
    "    for name in remotefiles:\n",
    "        print(\".\", end=\"\")\n",
    "        fin = open(name, \"r\")\n",
    "        body = fin.read()\n",
    "        # replace comment character\n",
    "        body = body.replace(\"//\", \"#\")\n",
    "        # replace zombie line endings\n",
    "        body = body.replace(\",\\r\\n\", \"\\r\\n\")\n",
    "        # comment out these lines\n",
    "        body = body.replace(\"CRS#1:\", \"#CRS#1\")\n",
    "        body = body.replace(\"CRS#2:\", \"#CRS#2\")\n",
    "        myfile = open(tmpfile, 'a')\n",
    "        myfile.write(body)\n",
    "        myfile.close()\n",
    "    print(\"\")\n",
    "\n",
    "    # SD\n",
    "    print(\"SD: \", end=\"\")\n",
    "    searchdir = os.path.join(sddir, \"%d\" % id)\n",
    "    sdfiles = [filename for filename in Path(searchdir).glob(\"**/\"+crns[id][\"sdpattern\"])]\n",
    "    print(\"found %d files\" % len(sdfiles))\n",
    "\n",
    "    for name in sdfiles:\n",
    "        print(\".\", end=\"\")\n",
    "        fin = open(name, \"r\")\n",
    "        body = fin.read()\n",
    "        # replace comment character\n",
    "        body = body.replace(\"//\", \"#\")\n",
    "        # replace zombie line endings\n",
    "        body = body.replace(\",\\r\\n\", \"\\r\\n\")\n",
    "        body = body.replace(\",\\n\", \"\\n\")\n",
    "        # comment out these lines\n",
    "        body = body.replace(\"CRS#1:\", \"#CRS#1\")\n",
    "        body = body.replace(\"CRS#2:\", \"#CRS#2\")\n",
    "        myfile = open(tmpfile, 'a')\n",
    "        myfile.write(body)\n",
    "        myfile.close()\n",
    "    print(\"\")\n",
    "\n",
    "    if \"colnames2\" in crns[id].keys():\n",
    "        # Read all lines. potentially varying no of columns \n",
    "        myfile = open(tmpfile, 'r')\n",
    "        lines = myfile.readlines()\n",
    "        myfile.close()\n",
    "        # Write in seperate files\n",
    "        myfile = open(tmpfile, 'w')\n",
    "        myfile2 = open(tmpfile2, 'w')\n",
    "        for line in lines:\n",
    "            split = line.split(\",\")\n",
    "            if len(split)==len(crns[id][\"colnames\"]):\n",
    "                myfile.write(line+\"\\n\")\n",
    "            if len(split)==len(crns[id][\"colnames2\"]):\n",
    "                myfile2.write(line+\"\\n\")\n",
    "        myfile.close()\n",
    "        myfile2.close()\n",
    "\n",
    "    # MERGE\n",
    "    df = pd.read_csv(tmpfile, sep=\",\", comment=\"#\", header=None, error_bad_lines=False, warn_bad_lines=True)\n",
    "    df.columns = crns[id][\"colnames\"]\n",
    "    if \"colnames2\" in crns[id].keys():\n",
    "        try:\n",
    "            df2 = pd.read_csv(tmpfile2, sep=\",\", comment=\"#\", header=None, \n",
    "                             error_bad_lines=False, warn_bad_lines=True)\n",
    "            df2.columns = crns[id][\"colnames2\"]\n",
    "            df = df2.append(df, sort=False)\n",
    "        except:\n",
    "            print(\"Problem in reading or appending data with diffferent column scenario\")\n",
    "            raise\n",
    "    df.datetime = pd.to_datetime(df.datetime, format=\"%Y/%m/%d %H:%M:%S\")\n",
    "    df = df.set_index(\"datetime\")\n",
    "    df.insert(loc=1, column=\"datetime\", value=df.index)\n",
    "    df = df.sort_index()\n",
    "    df = df[df.index >= \"2019-07-25\"]\n",
    "    dupl = df.index.duplicated(keep='first')\n",
    "    if np.any(dupl):\n",
    "        print(\"Contains %d duplicates\" % len(np.where(dupl)[0]))\n",
    "        df = df[~dupl]\n",
    "    fpath = os.path.join(trgdir, \"%d/%d_CRNS.txt\" % (id, id) )\n",
    "    df.to_csv(fpath, sep=\"\\t\", index=False, date_format=\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
